{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MbKvG5dKUf9c"
      },
      "source": [
        "# Zero-shot Text Classification"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qD_dvk7MUf9g"
      },
      "source": [
        "Your class names are likely already good descriptors of the text that you're looking to classify. With 🤗 SetFit, you can use these class names with strong pretrained Sentence Transformer models to get a strong baseline model without any training samples.\n",
        "\n",
        "This guide will show you how to perform zero-shot text classification."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip -q install transformers datasets evaluate setfit"
      ],
      "metadata": {
        "id": "1x0vptTmUmBv",
        "outputId": "cccb53c6-cc72-407d-bded-17043151109f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/480.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m337.9/480.6 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m480.6/480.6 kB\u001b[0m \u001b[31m8.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m84.0/84.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m179.3/179.3 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m7.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m1.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m89.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m69.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m44.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m836.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m6.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m12.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m6.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m81.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cEPgRrogUf9h"
      },
      "source": [
        "## Testing dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fNJH7A-cUf9i"
      },
      "source": [
        "We'll use the [dair-ai/emotion](https://huggingface.co/datasets/dair-ai/emotion) dataset to test the performance of our zero-shot model."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9Eydr2NvUf9j"
      },
      "outputs": [],
      "source": [
        "from datasets import load_dataset\n",
        "\n",
        "test_dataset = load_dataset(\"dair-ai/emotion\", \"split\", split=\"test\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0jJcr7H-Uf9k"
      },
      "source": [
        "This dataset stores the class names within the dataset `Features`, so we'll extract the classes like so:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3MewR4dVUf9l"
      },
      "outputs": [],
      "source": [
        "classes = test_dataset.features[\"label\"].names\n",
        "# => ['sadness', 'joy', 'love', 'anger', 'fear', 'surprise']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H2Qfhec_Uf9l"
      },
      "source": [
        "Otherwise, we could manually set the list of classes."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Qxn1fLa7Uf9m"
      },
      "source": [
        "## Synthetic dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d_apjihjUf9m"
      },
      "source": [
        "Then, we can use [get_templated_dataset()](https://huggingface.co/docs/setfit/main/en/reference/utility#setfit.get_templated_dataset) to synthetically generate a dummy dataset given these class names."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "yzgx8mphUf9m"
      },
      "outputs": [],
      "source": [
        "from setfit import get_templated_dataset\n",
        "\n",
        "train_dataset = get_templated_dataset()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Mk_u-RxBUf9n"
      },
      "outputs": [],
      "source": [
        "print(train_dataset)\n",
        "# => Dataset({\n",
        "#     features: ['text', 'label'],\n",
        "#     num_rows: 48\n",
        "# })\n",
        "print(train_dataset[0])\n",
        "# {'text': 'This sentence is sadness', 'label': 0}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ibNC5Z1jUf9n"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xKDP2NxsUf9n"
      },
      "source": [
        "We can use this dataset to train a SetFit model just like normal:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8IuAbrzdUf9n"
      },
      "outputs": [],
      "source": [
        "from setfit import SetFitModel, Trainer, TrainingArguments\n",
        "\n",
        "model = SetFitModel.from_pretrained(\"BAAI/bge-small-en-v1.5\")\n",
        "\n",
        "args = TrainingArguments(\n",
        "    batch_size=32,\n",
        "    num_epochs=1,\n",
        ")\n",
        "\n",
        "trainer = Trainer(\n",
        "    model=model,\n",
        "    args=args,\n",
        "    train_dataset=train_dataset,\n",
        "    eval_dataset=test_dataset,\n",
        ")\n",
        "trainer.train()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tqhI0y5AUf9n"
      },
      "source": [
        "```\n",
        "***** Running training *****\n",
        "  Num examples = 60\n",
        "  Num epochs = 1\n",
        "  Total optimization steps = 60\n",
        "  Total train batch size = 32\n",
        "{'embedding_loss': 0.2628, 'learning_rate': 3.3333333333333333e-06, 'epoch': 0.02}                                                                                 \n",
        "{'embedding_loss': 0.0222, 'learning_rate': 3.7037037037037037e-06, 'epoch': 0.83}                                                                                 \n",
        "{'train_runtime': 15.4717, 'train_samples_per_second': 124.098, 'train_steps_per_second': 3.878, 'epoch': 1.0}                                                     \n",
        "100%|█████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 60/60 [00:09<00:00,  6.35it/s]\n",
        "```\n",
        "\n",
        "Once trained, we can evaluate the model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "FPNUmIeNUf9o"
      },
      "outputs": [],
      "source": [
        "metrics = trainer.evaluate()\n",
        "print(metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KLrUUTxSUf9o"
      },
      "source": [
        "```\n",
        "***** Running evaluation *****\n",
        "{'accuracy': 0.591}\n",
        "```\n",
        "\n",
        "And run predictions:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a6vHOn0gUf9o"
      },
      "outputs": [],
      "source": [
        "preds = model.predict([\n",
        "    \"i am just feeling cranky and blue\",\n",
        "    \"i feel incredibly lucky just to be able to talk to her\",\n",
        "    \"you're pissing me off right now\",\n",
        "    \"i definitely have thalassophobia, don't get me near water like that\",\n",
        "    \"i did not see that coming at all\",\n",
        "])\n",
        "print([classes[idx] for idx in preds])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1w1yoiOJUf9o"
      },
      "outputs": [],
      "source": [
        "['sadness', 'joy', 'anger', 'fear', 'surprise']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0-gPBLs7Uf9p"
      },
      "source": [
        "These predictions all look right!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kypYlCKYUf9p"
      },
      "source": [
        "## Baseline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1KTdf-CcUf9p"
      },
      "source": [
        "To show that the zero-shot performance of SetFit works well, we'll compare it against a zero-shot classification model from `transformers`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qhVwa2IGUf9p"
      },
      "outputs": [],
      "source": [
        "from transformers import pipeline\n",
        "from datasets import load_dataset\n",
        "import evaluate\n",
        "\n",
        "# Prepare the testing dataset\n",
        "test_dataset = load_dataset(\"dair-ai/emotion\", \"split\", split=\"test\")\n",
        "classes = test_dataset.features[\"label\"].names\n",
        "\n",
        "# Set up the zero-shot classification pipeline from transformers\n",
        "# Uses 'facebook/bart-large-mnli' by default\n",
        "pipe = pipeline(\"zero-shot-classification\", device=0)\n",
        "zeroshot_preds = pipe(test_dataset[\"text\"], batch_size=16, candidate_labels=classes)\n",
        "preds = [classes.index(pred[\"labels\"][0]) for pred in zeroshot_preds]\n",
        "\n",
        "# Compute the accuracy\n",
        "metric = evaluate.load(\"accuracy\")\n",
        "transformers_accuracy = metric.compute(predictions=preds, references=test_dataset[\"label\"])\n",
        "print(transformers_accuracy)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G43Y7b_RUf9p"
      },
      "outputs": [],
      "source": [
        "{'accuracy': 0.3765}"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4P2XlIwkUf9p"
      },
      "source": [
        "With its 59.1% accuracy, the 0-shot SetFit heavily outperforms the recommended zero-shot model by `transformers`."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kZU3k9ooUf9p"
      },
      "source": [
        "## Prediction latency"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xyaNPzFNUf9p"
      },
      "source": [
        "Beyond getting higher accuracies, SetFit is much faster too. Let's compute the latency of SetFit with `BAAI/bge-small-en-v1.5` versus the latency of `transformers` with `facebook/bart-large-mnli`. Both tests were performed on a GPU."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VTrmIucSUf9q"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_t = time.time()\n",
        "pipe(test_dataset[\"text\"], batch_size=32, candidate_labels=classes)\n",
        "delta_t = time.time() - start_t\n",
        "print(f\"`transformers` with `facebook/bart-large-mnli` latency: {delta_t / len(test_dataset['text']) * 1000:.4f}ms per sentence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p-Av8DSjUf9q"
      },
      "source": [
        "```\n",
        "`transformers` with `facebook/bart-large-mnli` latency: 31.1765ms per sentence\n",
        "```"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZwTVnaTjUf9q"
      },
      "outputs": [],
      "source": [
        "import time\n",
        "\n",
        "start_t = time.time()\n",
        "model.predict(test_dataset[\"text\"])\n",
        "delta_t = time.time() - start_t\n",
        "print(f\"SetFit with `BAAI/bge-small-en-v1.5` latency: {delta_t / len(test_dataset['text']) * 1000:.4f}ms per sentence\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "965y3BNcUf9q"
      },
      "source": [
        "```\n",
        "SetFit with `BAAI/bge-small-en-v1.5` latency: 0.4600ms per sentence\n",
        "```\n",
        "\n",
        "So, SetFit with `BAAI/bge-small-en-v1.5` is 67x faster than `transformers` with `facebook/bart-large-mnli`, alongside being more accurate:\n",
        "\n",
        "![zero_shot_transformers_vs_setfit](https://github.com/huggingface/setfit/assets/37621491/33f574d9-c51b-4e02-8d98-6e04e18427ef)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "language_info": {
      "name": "python"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}